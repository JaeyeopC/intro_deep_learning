{"cells":[{"cell_type":"markdown","metadata":{"id":"UbbRuEuTiEBq"},"source":["# Text Processing and Word Embeddings\n","\n","Welcome to this new exercise! In this exercise, we will play around with text instead of images as before, using Recurrent Neural Networks. Generally, it is called Natural Language Processing (NLP) when dealing with text, speech, etc. But the data structure is very different from images, i.e., text is a string, while images consist of numbers. Hence, we need some preprocessing steps to transform the raw text into another data format. This notebook will introduce these basic concepts in NLP pipelines. Specifically, you will learn about:\n","\n","1. How to preprocess text classification datasets\n","2. How to create a simple word embedding layer that maps words to dense vectors"]},{"cell_type":"markdown","metadata":{"id":"eijoT6VziEBs"},"source":["## (Optional) Mount folder in Colab\n","\n","Uncomment the following cell to mount your gdrive if you are using the notebook in google colab:"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21474,"status":"ok","timestamp":1675162450689,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"},"user_tz":-60},"id":"aGqI2f3diEBs","outputId":"f4239803-dae7-4cd5-b850-5f724eb4608c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","['1_text_preprocessing_and_embedding.ipynb', '2_sentiment_analysis.ipynb', 'Optional-recurrent_neural_networks.ipynb', 'exercise_code', 'images', 'models']\n"]}],"source":["# Use the following lines if you want to use Google Colab\n","# We presume you created a folder \"i2dl\" within your main drive folder, and put the exercise there.\n","# NOTE: terminate all other colab sessions that use GPU!\n","# NOTE 2: Make sure the correct exercise folder (e.g exercise_11) is given.\n","\n","# \"\"\"\n","from google.colab import drive\n","import os\n","\n","gdrive_path='/content/gdrive/MyDrive/i2dl/exercise_11'\n","\n","# This will mount your google drive under 'MyDrive'\n","drive.mount('/content/gdrive', force_remount=True)\n","# In order to access the files in this notebook we have to navigate to the correct folder\n","os.chdir(gdrive_path)\n","# Check manually if all files are present\n","print(sorted(os.listdir()))\n","# \"\"\""]},{"cell_type":"markdown","metadata":{"id":"vBiN1doxiEBt"},"source":["### Set up PyTorch environment in colab\n","- (OPTIONAL) Enable GPU via Runtime --> Change runtime type --> GPU\n","- Uncomment the following cell if you are using the notebook in google colab:"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yS10F3byiEBt","outputId":"5e0239b7-9ce2-43e6-e6af-ef1a6a18670d","executionInfo":{"status":"ok","timestamp":1675162561006,"user_tz":-60,"elapsed":110319,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.11.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp38-cp38-linux_x86_64.whl (1637.0 MB)\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m147.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1636999168 bytes == 0x2fb6000 @  0x7f3f55dc4680 0x7f3f55de5824 0x5b3128 0x5bbc90 0x5f714c 0x64d800 0x527022 0x504866 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x5f5ee6 0x56bbe1 0x569d8a 0x5f60c3 0x56cc92 0x569d8a 0x5f60c3\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m124.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 2046255104 bytes == 0x648e0000 @  0x7f3f55dc4680 0x7f3f55de4da2 0x5f714c 0x64d800 0x527022 0x504866 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x5f5ee6 0x56bbe1 0x569d8a 0x5f60c3 0x56cc92 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a\n","tcmalloc: large alloc 1636999168 bytes == 0x2fb6000 @  0x7f3f55dc4680 0x7f3f55de5824 0x5f97c1 0x5f8ecc 0x504866 0x56bbe1 0x569d8a 0x5f60c3 0x56bbe1 0x569d8a 0x5f60c3 0x50b32c 0x5f6b7b 0x66731d 0x5f6706 0x571143 0x50b22e 0x570b82 0x569d8a 0x50b3a0 0x570b82 0x569d8a 0x50b3a0 0x56cc92 0x501044 0x56be83 0x501044 0x56be83 0x501044 0x56be83 0x5f5ee6\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.12.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp38-cp38-linux_x86_64.whl (22.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.11.0+cu113) (4.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.12.0+cu113) (2.25.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.12.0+cu113) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.12.0+cu113) (7.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0+cu113) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0+cu113) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0+cu113) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.12.0+cu113) (1.24.3)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.1+cu116\n","    Uninstalling torch-1.13.1+cu116:\n","      Successfully uninstalled torch-1.13.1+cu116\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.14.1+cu116\n","    Uninstalling torchvision-0.14.1+cu116:\n","      Successfully uninstalled torchvision-0.14.1+cu116\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.11.0+cu113 which is incompatible.\n","torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.11.0+cu113 torchvision-0.12.0+cu113\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboard==2.8.0\n","  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (2.25.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (3.4.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (57.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (2.16.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (3.19.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (1.0.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (1.3.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (0.6.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (1.51.1)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (1.21.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (1.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.8.0) (0.38.4)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0) (5.2.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.8.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.8.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard==2.8.0) (6.0.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard==2.8.0) (2022.12.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.8.0) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.8.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.8.0) (3.2.2)\n","Installing collected packages: tensorboard\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.9.1\n","    Uninstalling tensorboard-2.9.1:\n","      Successfully uninstalled tensorboard-2.9.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tensorboard-2.8.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-lightning==1.6.0\n","  Downloading pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.1/582.1 KB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (2022.11.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (4.64.1)\n","Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (1.11.0+cu113)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (2.8.0)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (6.0)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (21.3)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (1.21.6)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (4.4.0)\n","Collecting pyDeprecate<0.4.0,>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (3.8.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2.25.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch-lightning==1.6.0) (3.0.9)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (2.16.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.4.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.3.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.6.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.51.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (57.4.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.4.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.38.4)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.19.6)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.3.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.8.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (22.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (6.0.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.2.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (5.2.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (6.0.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.2.2)\n","Installing collected packages: pyDeprecate, torchmetrics, pytorch-lightning\n","Successfully installed pyDeprecate-0.3.2 pytorch-lightning-1.6.0 torchmetrics-0.11.1\n"]}],"source":["# Optional: install correct libraries in google colab\n","!python -m pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n","!python -m pip install tensorboard==2.8.0\n","!python -m pip install pytorch-lightning==1.6.0"]},{"cell_type":"markdown","metadata":{"id":"B7QV44ZYiEBt"},"source":["# 0. Setup\n","\n","As usual, we first import some packages to setup this notebook."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"J6oyUMOhiEBt","executionInfo":{"status":"ok","timestamp":1675162564455,"user_tz":-60,"elapsed":3454,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"}}},"outputs":[],"source":["import os\n","import torch\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","\n","from exercise_code.rnn.sentiment_dataset import (\n","    create_dummy_data,\n","    download_data\n",")\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# for auto-reloading external modules\n","# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"gtAXfOqniEBt"},"source":["# 1. Preprocessing a Text Classification Dataset\n","\n","As a starting point, let's load a dummy text classification dataset and have a sense of how it looks. We take these samples from the IMDb movie review dataset, which includes movie reviews and labels that show whether they are negative (0) or positive (1). You will investigate this task further in the second notebook.\n","\n","In this section, our goal is to create a text processing dataset. You are not required to write any code in this section. However, the concept introduced here is very important for working on NLP datasets in the future as well as in the rest of this exercise. \n","Take your time to understand the procedure here. \n","\n","First, let us download the data and take a look at some data samples."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fKSvtXkpiEBu","executionInfo":{"status":"ok","timestamp":1675162568654,"user_tz":-60,"elapsed":3677,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"}},"outputId":"b006d4cd-3b0d-433d-e60a-22530275bf03"},"outputs":[{"output_type":"stream","name":"stdout","text":["Text: This is the definitive movie version of Hamlet. Branagh cuts nothing, but there are no wasted moments.\n","Label: 1\n","\n","Text: Adrian Pasdar is excellent is this film. He makes a fascinating woman.\n","Label: 1\n","\n","Text: Smallville episode Justice is the best episode of Smallville ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! It's my favorite episode of Smallville! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !\n","Label: 1\n","\n","Text: no comment - stupid movie, acting average or worse... screenplay - no sense at all... SKIP IT!\n","Label: 0\n","\n","Text: Great movie - especially the music - Etta James - \"At Last\". This speaks volumes when you have finally found that special someone.\n","Label: 0\n","\n","Text: Ming The Merciless does a little Bardwork and a movie most foul!\n","Label: 0\n","\n"]}],"source":["i2dl_exercises_path = os.path.dirname(os.path.abspath(os.getcwd()))\n","data_root = os.path.join(i2dl_exercises_path, \"datasets\", \"SentimentData\")\n","path = download_data(data_root)\n","data = create_dummy_data(path)\n","for text, label in data:\n","    print('Text: {}'.format(text))\n","    print('Label: {}'.format(label))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"8TpVhLk1iEBu"},"source":["## 1.1 Tokenizing Data\n","\n","As seen above, we loaded 3 positive and 3 negative reviews. Since the basic semantic unit of text is a word, the first thing we need to do is **tokenizing** the dataset, which means converting each review to a list of words."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bybImaFiEBu","executionInfo":{"status":"ok","timestamp":1675162568655,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"}},"outputId":"f8d36dcd-a39b-423d-f7e1-73b4ebf14542"},"outputs":[{"output_type":"stream","name":"stdout","text":["(['this', 'is', 'the', 'definitive', 'movie', 'version', 'of', 'hamlet', 'branagh', 'cuts', 'nothing', 'but', 'there', 'are', 'no', 'wasted', 'moments'], 1) \n","\n","(['adrian', 'pasdar', 'is', 'excellent', 'is', 'this', 'film', 'he', 'makes', 'a', 'fascinating', 'woman'], 1) \n","\n","(['smallville', 'episode', 'justice', 'is', 'the', 'best', 'episode', 'of', 'smallville', 'it', 's', 'my', 'favorite', 'episode', 'of', 'smallville'], 1) \n","\n","(['no', 'comment', 'stupid', 'movie', 'acting', 'average', 'or', 'worse', 'screenplay', 'no', 'sense', 'at', 'all', 'skip', 'it'], 0) \n","\n","(['great', 'movie', 'especially', 'the', 'music', 'etta', 'james', 'at', 'last', 'this', 'speaks', 'volumes', 'when', 'you', 'have', 'finally', 'found', 'that', 'special', 'someone'], 0) \n","\n","(['ming', 'the', 'merciless', 'does', 'a', 'little', 'bardwork', 'and', 'a', 'movie', 'most', 'foul'], 0) \n","\n"]}],"source":["import re\n","\n","# use regular expression to split the sentence\n","# check https://docs.python.org/3/library/re.html for more information\n","def tokenize(text):\n","    return [s.lower() for s in re.split(r'\\W+', text) if len(s) > 0]\n","\n","tokenized_data = []\n","for text, label in data:\n","    tokenized_data.append((tokenize(text), label))\n","    print(tokenized_data[-1], '\\n')"]},{"cell_type":"markdown","metadata":{"id":"MuG5azXCiEBu"},"source":["## 1.2 Creating a Vocabulary\n","\n","We have converted the dataset into pairs of token lists and corresponding labels. But strings have varying lengths, which is hard to handle. It would be nice to represent words with numbers. So, we need to create a <b>vocabulary</b>, which is a dictionary that maps each word to an integer id.\n","\n","In large datasets, there are too many words, and most of them don't occur very frequently. One common approach we use to tackle this problem is to pick the most common N words from the dataset. Therefore, we restrict the number of words.\n","\n","First, let's compute the word frequencies in our dummy dataset. To compute frequencies, we use the [Counter](https://docs.python.org/3/library/collections.html#collections.Counter) data structure."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sdEddRF2iEBu","executionInfo":{"status":"ok","timestamp":1675162575987,"user_tz":-60,"elapsed":313,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"}},"outputId":"d08b6f43-f4b2-4946-d970-d4d4aed008eb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({'this': 3,\n","         'is': 4,\n","         'the': 4,\n","         'definitive': 1,\n","         'movie': 4,\n","         'version': 1,\n","         'of': 3,\n","         'hamlet': 1,\n","         'branagh': 1,\n","         'cuts': 1,\n","         'nothing': 1,\n","         'but': 1,\n","         'there': 1,\n","         'are': 1,\n","         'no': 3,\n","         'wasted': 1,\n","         'moments': 1,\n","         'adrian': 1,\n","         'pasdar': 1,\n","         'excellent': 1,\n","         'film': 1,\n","         'he': 1,\n","         'makes': 1,\n","         'a': 3,\n","         'fascinating': 1,\n","         'woman': 1,\n","         'smallville': 3,\n","         'episode': 3,\n","         'justice': 1,\n","         'best': 1,\n","         'it': 2,\n","         's': 1,\n","         'my': 1,\n","         'favorite': 1,\n","         'comment': 1,\n","         'stupid': 1,\n","         'acting': 1,\n","         'average': 1,\n","         'or': 1,\n","         'worse': 1,\n","         'screenplay': 1,\n","         'sense': 1,\n","         'at': 2,\n","         'all': 1,\n","         'skip': 1,\n","         'great': 1,\n","         'especially': 1,\n","         'music': 1,\n","         'etta': 1,\n","         'james': 1,\n","         'last': 1,\n","         'speaks': 1,\n","         'volumes': 1,\n","         'when': 1,\n","         'you': 1,\n","         'have': 1,\n","         'finally': 1,\n","         'found': 1,\n","         'that': 1,\n","         'special': 1,\n","         'someone': 1,\n","         'ming': 1,\n","         'merciless': 1,\n","         'does': 1,\n","         'little': 1,\n","         'bardwork': 1,\n","         'and': 1,\n","         'most': 1,\n","         'foul': 1})"]},"metadata":{},"execution_count":7}],"source":["from collections import Counter\n","\n","freqs = Counter()\n","for tokens, _ in tokenized_data:\n","    freqs.update(tokens)\n","\n","freqs"]},{"cell_type":"markdown","metadata":{"id":"i_S8xyzIiEBu"},"source":["To create the dictionary, let's select the most common 20 words to create a vocabulary. In addition to the words that appear in our data, we need to have two special words:\n","\n","- `<eos>` End of sequence symbol used for padding\n","- `<unk>` Words unknown in our vocabulary"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"-7oYZZRJiEBv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675164227380,"user_tz":-60,"elapsed":2,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"}},"outputId":"aa339cc3-f4d0-4437-f4ec-3caf32cdac0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["22\n"]},{"output_type":"execute_result","data":{"text/plain":["{'<eos>': 0,\n"," '<unk>': 1,\n"," 'is': 2,\n"," 'the': 3,\n"," 'movie': 4,\n"," 'this': 5,\n"," 'of': 6,\n"," 'no': 7,\n"," 'a': 8,\n"," 'smallville': 9,\n"," 'episode': 10,\n"," 'it': 11,\n"," 'at': 12,\n"," 'definitive': 13,\n"," 'version': 14,\n"," 'hamlet': 15,\n"," 'branagh': 16,\n"," 'cuts': 17,\n"," 'nothing': 18,\n"," 'but': 19,\n"," 'there': 20,\n"," 'are': 21}"]},"metadata":{},"execution_count":32}],"source":["print(len(vocab))\n","vocab = {'<eos>': 0, '<unk>': 1}\n","for token, freq in freqs.most_common(20):\n","    vocab[token] = len(vocab)\n","vocab\n","\n","# eos와 unk은 마킹용, 실제 데이터 = 20개 -> dataset만들때 문장에 이 특수문자 처리하기 위함"]},{"cell_type":"markdown","metadata":{"id":"ArYxaEYHiEBv"},"source":["## 1.3 Creating the Dataset\n","\n","Putting it all together, we can now create a dataset class. First, let's create index-label pairs:"]},{"cell_type":"code","source":[],"metadata":{"id":"OEYrlHxbY9Wc","executionInfo":{"status":"ok","timestamp":1675162576689,"user_tz":-60,"elapsed":2,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"xcmkJQ8GiEBv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675162577137,"user_tz":-60,"elapsed":2,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"}},"outputId":"fbbc4485-92e2-43c9-b5dc-5a8a73e648dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["[5, 2, 3, 13, 4, 14, 6, 15, 16, 17, 18, 19, 20, 21, 7, 1, 1]  ->  1\n","\n","[1, 1, 2, 1, 2, 5, 1, 1, 1, 8, 1, 1]  ->  1\n","\n","[9, 10, 1, 2, 3, 1, 10, 6, 9, 11, 1, 1, 1, 10, 6, 9]  ->  1\n","\n","[7, 1, 1, 4, 1, 1, 1, 1, 1, 7, 1, 12, 1, 1, 11]  ->  0\n","\n","[1, 4, 1, 3, 1, 1, 1, 12, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  ->  0\n","\n","[1, 3, 1, 1, 8, 1, 1, 1, 8, 4, 1, 1]  ->  0\n","\n"]}],"source":["indexed_data = []\n","for tokens, label in tokenized_data:\n","    # get( key, default value)\n","    indices = [vocab.get(token, vocab['<unk>']) for token in tokens]    \n","    # the token that is not in vocab get assigned <unk>\n","    indexed_data.append((indices, label))\n","    # Vocab의 freq가 index로 입력된 것.\n","    \n","\n","for indices, label in indexed_data:\n","    print(indices, ' -> ', label)\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"xUIpnq5WiEBv"},"source":["<div class=\"alert alert-success\"> \n","    <h3>Task: Check Code</h3>\n","    <p>We now use the PyTorch dataset class we provided in <code>exercise_code/rnn/sentiment_dataset.py</code> file. Please also take a look at the code.</p>\n"," </div>\n","    \n","\n","\n","Dataset class also reverse sorts the sequences with respect to the lengths. Thanks to this sorting, we can reduce the total number of padded elements, which means that we have less computations for padded values."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"WtKQ2WDliEBv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675162577562,"user_tz":-60,"elapsed":1,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"}},"outputId":"90ca1c71-32e4-4d74-8526-bae8d0d113fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'data': tensor([ 1,  4,  1,  3,  1,  1,  1, 12,  1,  5,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1]), 'label': tensor(0.)}\n","\n","{'data': tensor([ 5,  2,  3, 13,  4, 14,  6, 15, 16, 17, 18, 19, 20, 21,  7,  1,  1]), 'label': tensor(1.)}\n","\n","{'data': tensor([ 9, 10,  1,  2,  3,  1, 10,  6,  9, 11,  1,  1,  1, 10,  6,  9]), 'label': tensor(1.)}\n","\n","{'data': tensor([ 7,  1,  1,  4,  1,  1,  1,  1,  1,  7,  1, 12,  1,  1, 11]), 'label': tensor(0.)}\n","\n","{'data': tensor([1, 1, 2, 1, 2, 5, 1, 1, 1, 8, 1, 1]), 'label': tensor(1.)}\n","\n","{'data': tensor([1, 3, 1, 1, 8, 1, 1, 1, 8, 4, 1, 1]), 'label': tensor(0.)}\n","\n"]}],"source":["from exercise_code.rnn.sentiment_dataset import SentimentDataset\n","\n","combined_data = [\n","    (raw_text, tokens, indices, label)\n","    for (raw_text, label), (tokens, _), (indices, _)\n","    in zip(data, tokenized_data, indexed_data)\n","]\n","\n","dataset = SentimentDataset(combined_data)\n","\n","for elem in dataset:\n","    print(elem)\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"c0SjTN2IiEBv"},"source":["## 1.4 Minibatching\n","Note that in the dataset we created, not all sequences have the same length. Therefore, we cannot minibatch the data trivially. This means we cannot use a `DataLoader` class easily.\n","\n","<b>If you uncomment the following cell and run it, you will very likely get an error!</b>"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"TCp4OyNCiEBv","executionInfo":{"status":"ok","timestamp":1675162578734,"user_tz":-60,"elapsed":2,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"}}},"outputs":[],"source":["# loader = DataLoader(dataset, batch_size=3)\n","\n","# for batch in loader:\n","#     print(batch)"]},{"cell_type":"markdown","metadata":{"id":"SS0ck4n0iEBv"},"source":["<div class=\"alert alert-success\"> \n","    <h3>Task: Check Code</h3>\n","    <p>To solve the problem, we need to pad the sequences with <code> < eos > </code> tokens that we indexed as zero. To integrate this approach into the Pytorch <a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\" target=\"_blank\">Dataloader</a> class, we will make use of the <code>collate_fn</code> argument. For more details, check out the <code>collate</code> function in <code>exercise_code/rnn/sentiment_dataset</code>. </p>\n","    <p> In addition, we use the <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html\" target=\"_blank\">pad_sequence</a> that pads shorter sequences with 0. </p>\n"," </div>"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"vjVdn1Q5iEBv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675164008464,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"}},"outputId":"6b85e798-896f-4690-c125-c959e6f32928"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data: \n"," tensor([[ 1,  5,  9],\n","        [ 4,  2, 10],\n","        [ 1,  3,  1],\n","        [ 3, 13,  2],\n","        [ 1,  4,  3],\n","        [ 1, 14,  1],\n","        [ 1,  6, 10],\n","        [12, 15,  6],\n","        [ 1, 16,  9],\n","        [ 5, 17, 11],\n","        [ 1, 18,  1],\n","        [ 1, 19,  1],\n","        [ 1, 20,  1],\n","        [ 1, 21, 10],\n","        [ 1,  7,  6],\n","        [ 1,  1,  9],\n","        [ 1,  1,  0],\n","        [ 1,  0,  0],\n","        [ 1,  0,  0],\n","        [ 1,  0,  0]])\n","\n","Labels: \n"," tensor([0., 1., 1.])\n","\n","Sequence Lengths: \n"," tensor([20, 17, 16])\n","\n","\n","Data: \n"," tensor([[ 7,  1,  1],\n","        [ 1,  1,  3],\n","        [ 1,  2,  1],\n","        [ 4,  1,  1],\n","        [ 1,  2,  8],\n","        [ 1,  5,  1],\n","        [ 1,  1,  1],\n","        [ 1,  1,  1],\n","        [ 1,  1,  8],\n","        [ 7,  8,  4],\n","        [ 1,  1,  1],\n","        [12,  1,  1],\n","        [ 1,  0,  0],\n","        [ 1,  0,  0],\n","        [11,  0,  0]])\n","\n","Labels: \n"," tensor([0., 1., 0.])\n","\n","Sequence Lengths: \n"," tensor([15, 12, 12])\n","\n","\n"]}],"source":["from torch.nn.utils.rnn import pad_sequence\n","\n","def collate(batch):\n","    assert isinstance(batch, list)\n","    data = pad_sequence([b['data'] for b in batch])\n","    lengths = torch.tensor([len(b['data']) for b in batch])\n","    label = torch.stack([b['label'] for b in batch])\n","    return {\n","        'data': data,\n","        'label': label,\n","        'lengths': lengths\n","    }\n","\n","    # data -> 열로 들어감)\n","\n","loader = DataLoader(dataset, batch_size=3, collate_fn=collate)\n","for batch in loader:\n","    print('Data: \\n', batch['data']) # ['data'][:,0] -> 첫번째 문장\n","    print('\\nLabels: \\n', batch['label'])\n","    print('\\nSequence Lengths: \\n', batch['lengths'])\n","    print('\\n')"]},{"cell_type":"markdown","metadata":{"id":"_P9gcFOXiEBv"},"source":["We can see that these two batches have different length, this is how the reverse sort mentioned in `1.3 Creating the Dataset` benefits for less memory and less computation. "]},{"cell_type":"markdown","metadata":{"id":"C-ZcQYFGiEBv"},"source":["# 2. Embeddings\n","\n","In the previous section, we explored how to convert text into a sequence of integers. In this form, sequences are still not ready to be inputs of RNNs you implemented in the optional notebook. \n","\n","An integer representation is usually a one-hot encoding, while not the same since they are not equally weighted given only an integer. \n","\n","Moreover, it fails to express the semantic relations between words and the order of the words has no meaning. We would like a better representation to keep the semantic meaning of the word. For example, as shown in the following picture, the difference between man and woman and the difference between king and queen should be close, since the difference is only the gender. If we use a vector for each word, the above relation can be expressed as $vec(\\text{women})-vec(\\text{man}) \\approx vec(\\text{queen}) - vec(\\text{king})$. Usually we call such vector representations as embeddings.\n","\n","<img src='https://developers.google.com/machine-learning/crash-course/images/linear-relationships.svg' width=80% height=80%/>\n","\n","While one can use pre-trained embedding vectors such as [word2vec](https://arxiv.org/abs/1301.3781) or [GLoVe](https://nlp.stanford.edu/projects/glove/), in this exercise we use randomly initialized embedding vectors that will be trained from scratch together with our networks. As we train our model, it will learn the semantic relations between words."]},{"cell_type":"markdown","metadata":{"id":"4SNLILA4iEBv"},"source":["<div class=\"alert alert-info\">\n","\n","<h3> Task: Implement Embedding</h3>\n"," <p>In this part, you will implement a simple embedding layer. Embedding is a simple lookup table that stores a dense vector to represent each word in the vocabulary.</p> \n","\n"," <p>Your task is to implement the <code>Embedding</code> class in <code>exercise_code.rnn.rnn_nn</code> file. Once you are done, run the below cell to test your implementation. Note that we ensure eos embeddings to be zero by using the <code>padding_idx</code> argument.\n","\n"," </div>"]},{"cell_type":"code","source":[],"metadata":{"id":"vuJqNKgWYHtN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nAgWfHtSiEBv","executionInfo":{"status":"ok","timestamp":1675164092285,"user_tz":-60,"elapsed":423,"user":{"displayName":"Jay Chung","userId":"07183897499487652795"}},"outputId":"d3fb3aeb-c9ae-4a94-8aa3-f711412dc195"},"outputs":[{"output_type":"stream","name":"stdout","text":["22\n","6\n","i2dl_embedding tensor([[[-8.8646e-01,  6.9795e-01,  1.2481e+00,  ...,  5.1179e-01,\n","          -1.2484e+00,  6.6051e-01],\n","         [ 4.9618e-01, -3.5839e-01,  3.8317e-01,  ..., -6.3088e-01,\n","          -1.5114e-01, -3.7058e-01],\n","         [ 1.7647e-01, -1.6015e-01, -2.2169e+00,  ...,  1.9632e+00,\n","          -7.8271e-01, -1.8296e+00],\n","         [-2.4719e+00,  1.1572e+00,  1.2568e+00,  ...,  2.1768e-01,\n","           1.2891e-01,  1.5898e-01],\n","         [-8.8646e-01,  6.9795e-01,  1.2481e+00,  ...,  5.1179e-01,\n","          -1.2484e+00,  6.6051e-01],\n","         [-8.8646e-01,  6.9795e-01,  1.2481e+00,  ...,  5.1179e-01,\n","          -1.2484e+00,  6.6051e-01]],\n","\n","        [[ 2.7435e-01, -6.1684e-01, -2.0251e-01,  ..., -2.7858e-02,\n","           1.9580e+00,  3.5112e-01],\n","         [ 8.4677e-01, -6.6523e-01,  7.0135e-01,  ...,  1.0624e+00,\n","          -2.7124e-01,  5.3721e-02],\n","         [-5.5289e-01,  3.3802e-01, -4.2362e-01,  ..., -3.3800e+00,\n","          -8.3814e-01,  4.1767e-04],\n","         [-8.8646e-01,  6.9795e-01,  1.2481e+00,  ...,  5.1179e-01,\n","          -1.2484e+00,  6.6051e-01],\n","         [-8.8646e-01,  6.9795e-01,  1.2481e+00,  ...,  5.1179e-01,\n","          -1.2484e+00,  6.6051e-01],\n","         [-5.5112e-01, -8.3700e-01, -1.3121e-01,  ..., -1.2446e-01,\n","           2.1618e-02,  3.7006e-01]],\n","\n","        [[-8.8646e-01,  6.9795e-01,  1.2481e+00,  ...,  5.1179e-01,\n","          -1.2484e+00,  6.6051e-01],\n","         [-5.5112e-01, -8.3700e-01, -1.3121e-01,  ..., -1.2446e-01,\n","           2.1618e-02,  3.7006e-01],\n","         [-8.8646e-01,  6.9795e-01,  1.2481e+00,  ...,  5.1179e-01,\n","          -1.2484e+00,  6.6051e-01],\n","         [-8.8646e-01,  6.9795e-01,  1.2481e+00,  ...,  5.1179e-01,\n","          -1.2484e+00,  6.6051e-01],\n","         [ 8.4677e-01, -6.6523e-01,  7.0135e-01,  ...,  1.0624e+00,\n","          -2.7124e-01,  5.3721e-02],\n","         [-8.8646e-01,  6.9795e-01,  1.2481e+00,  ...,  5.1179e-01,\n","          -1.2484e+00,  6.6051e-01]],\n","\n","        ...,\n","\n","        [[-8.8646e-01,  6.9795e-01,  1.2481e+00,  ...,  5.1179e-01,\n","          -1.2484e+00,  6.6051e-01],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00]],\n","\n","        [[-8.8646e-01,  6.9795e-01,  1.2481e+00,  ...,  5.1179e-01,\n","          -1.2484e+00,  6.6051e-01],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00]],\n","\n","        [[-8.8646e-01,  6.9795e-01,  1.2481e+00,  ...,  5.1179e-01,\n","          -1.2484e+00,  6.6051e-01],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00],\n","         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n","           0.0000e+00,  0.0000e+00]]], grad_fn=<IndexBackward0>)\n","i2dl_embedding torch.Size([20, 6, 16])\n","pytorch_embedding torch.Size([20, 6, 16])\n","Difference between outputs: 0.0\n","Test passed :)!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":30}],"source":["import torch.nn as nn\n","\n","from exercise_code.rnn.rnn_nn import Embedding\n","from exercise_code.rnn.tests import embedding_output_test\n","\n","\n","i2dl_embedding = Embedding(len(vocab), 16, padding_idx=0)\n","pytorch_embedding = nn.Embedding(len(vocab), 16, padding_idx=0)\n","\n","### data set에서 vocab길이 처리\n","\n","loader = DataLoader(dataset, batch_size=len(dataset), collate_fn=collate)\n","\n","for batch in loader:\n","    # print(batch['data'])\n","    x = batch['data']\n","print(\"i2dl_embedding\", i2dl_embedding(x))\n","print(\"i2dl_embedding\", i2dl_embedding(x).size())\n","print(\"pytorch_embedding\", pytorch_embedding(x).size())\n","# print(x.size())\n","embedding_output_test(i2dl_embedding, pytorch_embedding, x)\n","\n","# output : [단어들, 배치사이즈, 임베딩된 단어들 차원]\n"]},{"cell_type":"markdown","metadata":{"id":"kowDVYsciEBv"},"source":["# 3. Conclusion\n","\n","In this notebook, you learned how to prepare text data and how to create an embedding layer. In the next notebook, you will combine your Embedding and RNN implementations to create a sentiment analysis network!"]},{"cell_type":"code","source":[],"metadata":{"id":"sfd-WnDsUSEC"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["UbbRuEuTiEBq","eijoT6VziEBs","vBiN1doxiEBt","B7QV44ZYiEBt","gtAXfOqniEBt","8TpVhLk1iEBu","MuG5azXCiEBu","ArYxaEYHiEBv","c0SjTN2IiEBv","kowDVYsciEBv"]},"kernelspec":{"display_name":"i2dl","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:32:50) [MSC v.1929 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"ae3aae73068e3f6c78354faadc00aa3f23e0713f86a27300232dd83e2bc002d8"}}},"nbformat":4,"nbformat_minor":0}